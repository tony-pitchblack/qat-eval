model:
  embedding_dim: 256
  hidden_size: 256
  num_layers: 2
  dropout: 0.2
  bidirectional: true
  pad_idx: 0
  max_seq_len: 512
  embedding_dropout: 0.1

dataset:
  max_vocab_size: 50000
  min_freq: 2

training:
  batch_size: 32
  epochs: 3
  lr: 0.001
  weight_decay: 0.0

